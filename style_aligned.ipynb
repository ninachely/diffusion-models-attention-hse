{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/google/style-aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a83027",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "repo_dir = Path(\"style-aligned\")\n",
    "sys.path.append(str(repo_dir.resolve()))\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import itertools\n",
    "import mediapy as media\n",
    "\n",
    "from diffusers import StableDiffusionXLPipeline, DDIMScheduler\n",
    "import sa_handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9ac7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = DDIMScheduler(\n",
    "    beta_start=0.00085,\n",
    "    beta_end=0.012,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    clip_sample=False,\n",
    "    set_alpha_to_one=False,\n",
    ")\n",
    "\n",
    "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    torch_dtype=torch.float16,\n",
    "    variant=\"fp16\",\n",
    "    use_safetensors=True,\n",
    "    scheduler=scheduler,\n",
    ").to(\"cuda\")\n",
    "\n",
    "pipe.enable_vae_slicing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dc40bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "handler = sa_handler.Handler(pipe)\n",
    "\n",
    "def run_sa(prompts, sa_args, seed=0, num_inference_steps=30, guidance_scale=7.5):\n",
    "    g = torch.Generator(device=\"cpu\")\n",
    "    g.manual_seed(int(seed))\n",
    "    handler.register(sa_args)\n",
    "    images = pipe(\n",
    "        prompts,\n",
    "        generator=g,\n",
    "        num_inference_steps=int(num_inference_steps),\n",
    "        guidance_scale=float(guidance_scale),\n",
    "    ).images\n",
    "    handler.remove()\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd40d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompts = [\n",
    "    \"a toy train\",\n",
    "    \"a toy airplane\",\n",
    "    \"a toy bicycle\",\n",
    "    \"a toy car\",\n",
    "    \"a toy boat\",\n",
    "]\n",
    "\n",
    "style_prompt = \"macro photo, 3d game asset\"\n",
    "\n",
    "prompts = [p + \", \" + style_prompt for p in base_prompts]\n",
    "prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    \"share_group_norm\": [False, True],\n",
    "    \"share_layer_norm\": [False, True],\n",
    "    \"share_attention\": [True],\n",
    "    \"adain_queries\": [True],\n",
    "    \"adain_keys\": [True],\n",
    "    \"adain_values\": [False],\n",
    "    \"only_self_level\": [0.0, 0.5],\n",
    "    \"shared_score_shift\": [0.0, math.log(2)],\n",
    "    \"shared_score_scale\": [1.0],\n",
    "    \"full_attention_share\": [False],\n",
    "}\n",
    "\n",
    "keys = list(grid.keys())\n",
    "values = [grid[k] for k in keys]\n",
    "\n",
    "results = []\n",
    "\n",
    "for combo in itertools.product(*values):\n",
    "    cfg = dict(zip(keys, combo))\n",
    "    sa_args = sa_handler.StyleAlignedArgs(\n",
    "        share_group_norm=cfg[\"share_group_norm\"],\n",
    "        share_layer_norm=cfg[\"share_layer_norm\"],\n",
    "        share_attention=cfg[\"share_attention\"],\n",
    "        adain_queries=cfg[\"adain_queries\"],\n",
    "        adain_keys=cfg[\"adain_keys\"],\n",
    "        adain_values=cfg[\"adain_values\"],\n",
    "        full_attention_share=cfg[\"full_attention_share\"],\n",
    "        shared_score_scale=cfg[\"shared_score_scale\"],\n",
    "        shared_score_shift=cfg[\"shared_score_shift\"],\n",
    "        only_self_level=cfg[\"only_self_level\"],\n",
    "    )\n",
    "    images = run_sa(\n",
    "        prompts,\n",
    "        sa_args,\n",
    "        seed=10,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=7.5,\n",
    "    )\n",
    "    results.append((cfg, images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f50e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cfg_to_title(cfg):\n",
    "    return (\n",
    "        f\"GN={int(cfg['share_group_norm'])} \"\n",
    "        f\"LN={int(cfg['share_layer_norm'])} \"\n",
    "        f\"only_self={cfg['only_self_level']} \"\n",
    "        f\"shift={round(cfg['shared_score_shift'],3)}\"\n",
    "    )\n",
    "\n",
    "for cfg, images in results:\n",
    "    titles = [cfg_to_title(cfg)] + [\"\"] * (len(images) - 1)\n",
    "    media.show_images(images, titles=titles, height=192)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
